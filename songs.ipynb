{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA 2018 -  â€œHappinessâ€ Share it through music.\n",
    "\n",
    "#### Andres Montero, Ariel Alba, Diego Iriarte\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to find the relationships between tweets and music, specifically we focus on tweets which reflect a positive sentiment or mood and we'll relate them to the kind of music those people listen to. We believe that music preferences vary depending on people's mood, so we can detect what kind of music people tend to listen to when they are feeling happy or posting tweets with positive sentiment, which in our case are equivalent.\n",
    "For it, we'll work with two datasets:\n",
    "* FMA: A Dataset For Music Analysis\n",
    "* Sentiment140 dataset with 1.6 million tweets\n",
    "\n",
    "Tweets dataset is a labeled set, indicating whether each tweet has a positive sentiment or not.\n",
    "In order to define whether the proposed idea is feasible or not, we follow these steps:\n",
    "\n",
    "**A)** Preprocessing and analyzing FMA dataset. Gather the data that will be used, the dataset is very extense and we must focus on the data that will be used for our study. We clean the data, define the type of variables, normalize them and deal with missing values. From the cleaned data, we get some statistical information of the dataset, such as most listened songs, albums and we try to find some relationships between some information of the dataset such as: danceability, energy, number of times listened, location and others.\n",
    "\n",
    "**B)** Loading and analyzing of Sentiment140 dataset. We will only focus on tweets which are labeled as positive sentiment and the approach. The dataset contains few information about the tweets such as date, sentiment, userID and tweet, and is limited to tweets of yar 2009. Before doing any further preprocessing of such dataset we decided to check the possible relationships that we could find with FMA dataset.\n",
    "\n",
    "\n",
    "**C)** Find relationships between both datasets. It is important to identify whether the idea of the project is feasible or not. For the idea to be feasible, we need to find a considerable number of positive tweets which are somehow related to music or songs. To measure this relationships our approach is the following:\n",
    "* Count how many tweets link to a song link\n",
    "* Count how many tweets explicitly say spotify on it.\n",
    "* Find words related to music contained in the tweets (may be a difficult task)\n",
    "\n",
    "\n",
    "**D)** In case, our two first approaches to find the relationships between both datasets don't succeed, we may not be able to try with the third one due to time contraints and task difficulty. If thi is the scenario, the project scope will be reduced and will mostly focus on the FMA dataset and a specific event in the past years which may caused an impact on music production and preferences. Such scenario will be defined according to the insights found in part A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import reverse_geocoder as rg\n",
    "import os.path\n",
    "import ast\n",
    "import seaborn as sns\n",
    "\n",
    "from helpers import *\n",
    "from datetime import datetime, date, time\n",
    "from scipy import stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Preprocessing and Analyzing FMA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First part consists of loading the data that is needed for the analysis, cleaning and storing them in dataFrames so we can further work with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = './data/'\n",
    "MUSIC_DIR = '{dir}{file}/'.format(dir=DATA_DIR, \n",
    "                                  file='fma_metadata')\n",
    "PKL_DIR = '{dir}{file}/'.format(dir=DATA_DIR, \n",
    "                               file='pkl')\n",
    "\n",
    "# True if we want to to execute the clean phase and to force \n",
    "# saving the cleaned file\n",
    "CLEAN_PHASE = True\n",
    "DEBUG = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    echonest_path = '{dir}{file}'.format(dir=MUSIC_DIR, \n",
    "                                         file='echonest.csv')\n",
    "    features_path = '{dir}{file}'.format(dir=MUSIC_DIR,\n",
    "                                         file='features.csv')\n",
    "    genres_path = '{dir}{file}'.format(dir=MUSIC_DIR,\n",
    "                                       file='genres.csv')\n",
    "    tracks_path = '{dir}{file}'.format(dir=MUSIC_DIR,\n",
    "                                       file='tracks.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define which variables, type of variables and name of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    # Load datasets into pandas dataframes\n",
    "    echonest_col_names=['track_id', 'danceability', 'energy',\n",
    "                        'valence', 'artist_latitude',\n",
    "                        'artist_longitude', 'artist_name',\n",
    "                        'artist_discovery', 'artist_family',\n",
    "                        'artist_hotness', 'song_currency', \n",
    "                        'song_hotness']\n",
    "    \n",
    "    echonest_dtypes = {'track_id': int, 'danceability': float, \n",
    "                       'energy': float, 'valence': float,\n",
    "                       'artist_latitude': float, 'artist_longitude': float,\n",
    "                       'artist_name': str, 'artist_discovery': float, \n",
    "                       'artist_family': float, 'artist_hotness': float,\n",
    "                       'song_currency': float, 'song_hotness': float}\n",
    "    \n",
    "    echonest_df = pd.read_csv(echonest_path, names=echonest_col_names,\n",
    "                              header=3, dtype=echonest_dtypes, \n",
    "                              usecols=[0, 2, 3, 8, 11, 13, 14,\n",
    "                                       21, 22, 23, 24, 25])\n",
    "\n",
    "    genres_dtypes = {'genre_id': int, '#tracks': int, \n",
    "                     'parent': int, 'top_level': int}\n",
    "    \n",
    "    genres_df = pd.read_csv(genres_path, dtype=genres_dtypes)\n",
    "    \n",
    "    track_col_names = ['track_id', 'album_date_created',\n",
    "                       'album_date_released', 'album_id',\n",
    "                       'album_listens', 'album_title', \n",
    "                       'artist_id', 'artist_latitude',\n",
    "                       'artist_longitude', 'artist_name',\n",
    "                       'track_duration', 'track_genre_top',\n",
    "                       'track_genres_all', 'track_language', \n",
    "                       'track_listens', 'track_tags', \n",
    "                       'track_title']\n",
    "\n",
    "    tracks_dtypes = {'track_id': int, 'album_date_created': str,\n",
    "                     'album_date_released': str, \n",
    "                     'album_id': int, 'album_listens': int, \n",
    "                     'album_title': str, 'artist_id': int,\n",
    "                     'artist_latitude': float, 'artist_longitude': float,\n",
    "                     'artist_name': str, 'track_duration': int, \n",
    "                     'track_genre_top': str, 'track_genres_all': str, \n",
    "                     'track_language': str, 'track_listens': int,\n",
    "                     'track_tags': str, 'track_title': str}\n",
    "\n",
    "    tracks_df = pd.read_csv(tracks_path, names=track_col_names,\n",
    "                            header=2, usecols=[0, 2, 3, 6, 8, 11,\n",
    "                                               21, 22, 24, 26, 38, \n",
    "                                               40, 41, 45, 47, 51,\n",
    "                                               52])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tracks clean phase\n",
    "if CLEAN_PHASE:\n",
    "    # Transforms str to datetime\n",
    "    tracks_df['album_date_released'] = pd.to_datetime( \\\n",
    "                                            tracks_df['album_date_released'])\n",
    "    tracks_df['album_date_created'] = pd.to_datetime( \\\n",
    "                                            tracks_df['album_date_created'])\n",
    "    # Transform str to list\n",
    "    tracks_df['track_tags'] = tracks_df['track_tags'] \\\n",
    "                                .apply(lambda x: ast.literal_eval(x))\n",
    "    tracks_df['track_genres_all'] = tracks_df['track_genres_all'] \\\n",
    "                                .apply(lambda x: ast.literal_eval(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Normalize the dataFrames and remove redundant information. We merge information gathered in two different dataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    # Normalize dataframes to take out redundancy\n",
    "    \n",
    "    # Join echonist data to tracks\n",
    "    echo_tracks = echonest_df.merge(tracks_df, left_on='track_id', \n",
    "                                    right_on='track_id', how='outer')\n",
    "    \n",
    "    print(len(echo_tracks))\n",
    "     \n",
    "    # Select main columns to create new df\n",
    "    artists_df = echo_tracks[['artist_id', 'artist_name_x',\n",
    "                              'artist_latitude_x', 'artist_longitude_x', \n",
    "                              'artist_discovery', 'artist_family', \n",
    "                              'artist_hotness', 'artist_latitude_y',\n",
    "                              'artist_longitude_y', 'artist_name_y']].copy()\n",
    "\n",
    "    albums_df = echo_tracks[['album_id', 'album_date_created',\n",
    "                             'album_date_released', 'album_title',\n",
    "                             'album_listens']].copy()\n",
    "    \n",
    "    tracks_df = echo_tracks[['track_id', 'track_title', \n",
    "                             'track_duration', 'artist_id', \n",
    "                             'album_id', 'track_genre_top',\n",
    "                             'track_genres_all','track_language',\n",
    "                             'track_listens', 'track_tags',\n",
    "                             'danceability', 'energy',\n",
    "                             'valence', 'song_currency',\n",
    "                             'song_hotness']].copy()\n",
    "    \n",
    "    # Drop duplicates\n",
    "    artists_df = artists_df.drop_duplicates('artist_id')\n",
    "    albums_df = albums_df.drop_duplicates('album_id')\n",
    "    \n",
    "    # Reset Index\n",
    "    artists_df = artists_df.reset_index(drop=True)\n",
    "    albums_df = albums_df.reset_index(drop=True)\n",
    "    \n",
    "    # Clean listen count\n",
    "    albums_df['album_listens'] = albums_df['album_listens'] \\\n",
    "                                    .apply(lambda x : neg_to_zero(x))\n",
    "    \n",
    "    tracks_df['track_listens'] = tracks_df['track_listens'] \\\n",
    "                                    .apply(lambda x : neg_to_zero(x))\n",
    "    \n",
    "    # Artist name different on echonest and FullMusicArchive\n",
    "    if DEBUG:\n",
    "        name_comp = not_eq_ign_case(artists_df['artist_name_x'],\n",
    "                                    artists_df['artist_name_y'])\n",
    "        artist_name_diff = artists_df[name_comp]\n",
    "        \n",
    "        print('# Different artist names: {}\\n' \\\n",
    "                  .format(len(artist_name_diff)))\n",
    "\n",
    "        print('Example:\\n{}'.format(artist_name_diff[['artist_name_x',\n",
    "                                                      'artist_name_y']].head(3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artist location different on echonest and FullMusicArchive\n",
    "if DEBUG and CLEAN_PHASE:\n",
    "    lat_comp = artists_df['artist_latitude_x'] != artists_df['artist_latitude_y']\n",
    "    long_comp = artists_df['artist_longitude_x'] != artists_df['artist_longitude_y']\n",
    "    latlong_comp = lat_comp | long_comp\n",
    "    latlong_diff = artists_df[latlong_comp]\n",
    "\n",
    "    print('# Different Lat Long values: {}\\n' \\\n",
    "              .format(len(latlong_diff)))\n",
    "\n",
    "    print('Example:\\n{}'.format(artist_name_diff[['artist_latitude_x',\n",
    "                                                  'artist_latitude_y',\n",
    "                                                  'artist_longitude_x',\n",
    "                                                  'artist_longitude_y']].head(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Echonest clean phase \n",
    "if CLEAN_PHASE:\n",
    "    # Get city, state, country from artist longitude and latitude\n",
    "    cities=[]\n",
    "    states=[]\n",
    "    countries=[]\n",
    "    \n",
    "    for i in range (0, len(artists_df)):\n",
    "        if np.isnan(artists_df.artist_latitude_y[i]):\n",
    "            city = np.nan\n",
    "            state = np.nan\n",
    "            country = np.nan\n",
    "        else:\n",
    "            coordinates = (artists_df.artist_latitude_y[i], \n",
    "                           artists_df.artist_longitude_y[i])\n",
    "            results = rg.search(coordinates, mode=1)\n",
    "            city = results[0]['name']\n",
    "            state = results[0]['admin1']\n",
    "            country = results[0]['cc']\n",
    "        \n",
    "        cities.append(city)\n",
    "        states.append(state)\n",
    "        countries.append(country)\n",
    "    \n",
    "    artists_df.insert(loc=5, column='city', \n",
    "                      value=pd.Series(cities))\n",
    "    artists_df.insert(loc=6, column='state',\n",
    "                      value=pd.Series(states))\n",
    "    artists_df.insert(loc=7, column='country', \n",
    "                      value=pd.Series(countries))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read  and wirte files depending on the existance of own path\n",
    "echonest_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                        file='echonest_df.pkl')\n",
    "genres_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                     file='genres_df.pkl')\n",
    "albums_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                     file='albums_df.pkl')\n",
    "artists_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                     file='artists_df.pkl')\n",
    "tracks_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                      file='tracks_df.pkl')\n",
    "\n",
    "if CLEAN_PHASE:\n",
    "    genres_df.to_pickle(genres_df_path)\n",
    "elif os.path.exists(echonest_df_path):\n",
    "    genres_df = pd.read_pickle(genres_df_path)\n",
    "else:\n",
    "    print('There is no genres pandas data')\n",
    "    \n",
    "if CLEAN_PHASE:\n",
    "    albums_df.to_pickle(albums_df_path)\n",
    "elif os.path.exists(albums_df_path):\n",
    "    albums_df = pd.read_pickle(albums_df_path)\n",
    "else:\n",
    "    print('There is no albums pandas data')\n",
    "    \n",
    "if CLEAN_PHASE:\n",
    "    artists_df.to_pickle(artists_df_path)\n",
    "elif os.path.exists(artists_df_path):\n",
    "    artists_df = pd.read_pickle(artists_df_path)\n",
    "else:\n",
    "    print('There is no albums pandas data')\n",
    "    \n",
    "if CLEAN_PHASE:\n",
    "    tracks_df.to_pickle(tracks_df_path)\n",
    "elif os.path.exists(tracks_df_path):\n",
    "    tracks_df = pd.read_pickle(tracks_df_path)\n",
    "else:\n",
    "    print('There is no albums tracks data')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify the missing values on artist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Artists size: {}'.format(len(artists_df)))\n",
    "if DEBUG: print('\\nNaN count by column:\\n{}' \\\n",
    "                .format(artists_df.isna().sum(axis=0)))\n",
    "artists_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify the missing values on albums_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Albums size: {}'.format(len(albums_df)))\n",
    "if DEBUG: print('\\nNaN count by column:\\n{}' \\\n",
    "                .format(albums_df.isna().sum(axis=0)))\n",
    "albums_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify the missing values on echonest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Echonest size: {}'.format(len(echonest_df)))\n",
    "if DEBUG: print('\\nNaN count by column:\\n{}' \\\n",
    "                .format(echonest_df.isna().sum(axis=0)))\n",
    "echonest_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify the missing values on genres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Genres size: {}'.format(len(genres_df)))\n",
    "if DEBUG: print('\\nNaN count by column:\\n{}' \\\n",
    "                .format(genres_df.isna().sum(axis=0)))\n",
    "genres_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify the missing values on tracks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tracks size: {}'.format(len(tracks_df)))\n",
    "if DEBUG: print('\\nNaN count by column:\\n{}' \\\n",
    "                .format(tracks_df.isna().sum(axis=0)))\n",
    "tracks_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we will see the top 10 countries were the music is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data to have the entire data frame\n",
    "tracks_echonest = echonest_df.merge(tracks_df, left_on='track_id', \n",
    "                                    right_on='track_id', how='right')\n",
    "tracks_echonest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_artist = tracks_df.merge(artists_df, left_on='artist_id', \n",
    "                               right_on='artist_id')\n",
    "country_grouped = track_artist.groupby(track_artist['country']).size()\n",
    "country_top10 = country_grouped.sort_values(ascending=False) \\\n",
    "                                     .head(10)\n",
    "country_top10.plot(kind='bar', \n",
    "                   title=\"Top 10 countries that produce tracks\")\n",
    "plt.ylabel('Number of Tracks')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_grouped = albums_df.groupby(albums_df['album_id']) \\\n",
    "                          .first()[['album_title', 'album_listens']]\n",
    "albums_top10 = albums_grouped.sort_values(by='album_listens', \n",
    "                                          ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Top 10 Albums listened\")\n",
    "plt.grid()\n",
    "ax = sns.barplot(x='album_title', y= 'album_listens',\n",
    "                 data=albums_top10)\n",
    "plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_grouped = tracks_df.groupby(tracks_df['track_id']) \\\n",
    "                          .first()[['track_title', 'track_listens']]\n",
    "tracks_top10 = tracks_grouped.sort_values(by='track_listens', \n",
    "                                          ascending=False).head(10)\n",
    "\n",
    "albums_top10.plot(x='album_title', kind='bar', title=\"Top 10 Albums\")\n",
    "plt.grid()\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Top 10 tracks listened\")\n",
    "plt.grid()\n",
    "ax = sns.barplot(x='track_title', y= 'track_listens',\n",
    "                 data=tracks_top10)\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# albums_top10.plot(x='album_title', kind='bar', title=\"Top 10 Albums\")\n",
    "# plt.grid()\n",
    "# plt.figure(figsize=(15, 8))\n",
    "# plt.title(\"Top 10 tracks listened\")\n",
    "# plt.grid()\n",
    "# ax = sns.barplot(x='track_title', y= 'track_listens',\n",
    "#                  data=tracks_top10)\n",
    "tracks_top10.plot(x='track_title', kind='bar', title='Top 10 tracks listened')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation between danceability and duration of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracks_df.insert(loc=15, column='track_duration_minutes',\n",
    "                 value=(tracks_df['track_duration'] / 60))\n",
    "\n",
    "tracks_df['track_duration_minutes'] = pd.to_numeric(tracks_df['track_duration_minutes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervals = pd.IntervalIndex.from_arrays([0, 2, 4], \n",
    "#                                          [2, 4, 1000], closed='left')\n",
    "\n",
    "# tracks_df['duration_class'] = pd.cut(tracks_df['track_duration_minutes'], \n",
    "#                                      bins=intervals)\n",
    "\n",
    "tracks_df['track_duration_minutes'] = tracks_df['track_duration_minutes'] \\\n",
    "                                                .apply(lambda x : np.rint(x))\n",
    "sns.regplot(x='danceability', y='track_duration_minutes',\n",
    "            data=tracks_df, ci=95, \n",
    "            line_kws = {'color': 'green'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_coeff = stats.spearmanr(tracks_df['danceability'], \n",
    "                                 tracks_df['track_duration_minutes'])\n",
    "spearman_coeff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation between valence and other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valence refers to the degree of positive or negative emotions one perceives from a song. We'll try to find some relations between such varible and others.\n",
    "Relation between track_listens and valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='valence', y='track_listens',\n",
    "            data=tracks_df, ci=95, \n",
    "            line_kws = {'color': 'green'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the plot, it is difficult to find a relationships between the valence of the song and the number of listens. We also tried to find relation between valence and energy, or valence and danceability and we found that such relationships are highly variable and do not show any dependance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean value of valence per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_valence=tracks_df.groupby('track_genre_top', as_index=False)['valence'].mean()\n",
    "genre_valence.plot(x='track_genre_top', kind='bar', title='Valence per genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_album = tracks_df.merge(albums_df, left_on='album_id',\n",
    "                              right_on='album_id')\n",
    "\n",
    "genre_year = track_album[['track_genre_top', 'album_date_released']]\n",
    "genre_year.insert(loc=2, column='album_released_year',\n",
    "                  value=(genre_year['album_date_released'].dt.year))\n",
    "genre_year.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_genre = genre_year.groupby(genre_year['track_genre_top']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genre_sorted = top_genre.sort_values(ascending=False).head(10)\n",
    "top_genre_sorted.plot(kind='bar', title=\"Top 10 Genres\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_album.sort_values(by='album_date_released', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_album.sort_values(by='album_date_created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Loading and analyzing of Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import reverse_geocoder as rg\n",
    "import os.path\n",
    "import ast\n",
    "import seaborn as sns\n",
    "\n",
    "from helpers import *\n",
    "from datetime import datetime, date, time\n",
    "from scipy import stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_col_names=['sentiment', 'ID', 'Date',\n",
    "                        'user', 'text']\n",
    "\n",
    "tweets_dtypes = {'sentiment': int, 'ID': int, \n",
    "                       'Date': str, 'user': str,\n",
    "                       'text': str }\n",
    "\n",
    "tweets_df = pd.read_csv(DATA_DIR + '/tweets.csv', names=tweets_col_names,\n",
    "                              dtype=tweets_dtypes, \n",
    "                              usecols=[0, 1, 2, 4, 5], encoding='latin1')\n",
    "# tweets_df['Date'] = pd.to_datetime(tweets_df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Find relationships between both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = tweets_df[tweets_df.text.str.contains('Spotify')]\n",
    "f2 = tweets_df[tweets_df.text.str.contains('spotify')]\n",
    "tweets_spotify = pd.concat([f1,f2])\n",
    "num_tweets_spotify = tweets_spotify.count()\n",
    "num_tweets_spotify[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_tweets_total=tweets_df.count()\n",
    "num_tweets_total[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_spotify_pergentage = num_tweets_spotify[0]*100/num_tweets_total[0]\n",
    "tweets_spotify_pergentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have less than 0.017% of tweets that relate to a song, therefore we conclude that there is not enough data on our training \n",
    "to have a confident model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is not enough data in our training data set that relates tweets with spotify, less than 0.017%. Therefore we conclulde that this approach is not feasible. Because the previous aproach was not feasible, we decide to work with the music data set and related to an important event of the last decade to analyze if/how the music played a roll on this event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D) Redefine Project Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the music dataset, most of it is from artist in the US, and one of the biggest events in the last decade is the election of the United States of 2016 when Donald Trump was elected as president.\n",
    "With this in mind the new research question is the following:\n",
    "##### By analyzing the information of the music data set since 2012-2016, find the relation that the music may have had on this event, analyzing the top genre of that period, top tracks, and most important the valence and energy of the songs to try to find out how people of the US fell in that specific time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Then the next approach will be to compare this data with information we will obtain trhought the API spotify wit music records since end of 2016, and try to find how people feel on this period. And if posible provide a prediction of what kind of music (genre, energy, valence) people of the US will listen in the following years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elections of trump were on november 2016 so we will have pre-trump period with 5 years of music data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_trump = track_album[(track_album.album_date_created.dt.year >= 2012) & (track_album.album_date_created.dt.year <= 2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trump.album_date_created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trump_grouped = pre_trump.groupby(tracks_df['track_id']) \\\n",
    "                          .first()[['track_title', 'track_listens']]\n",
    "pre_trump_tracks_top10 = pre_trump_grouped.sort_values(by='track_listens', \n",
    "                                          ascending=False).head(10)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2,  constrained_layout=True, figsize=(12,5))\n",
    "\n",
    "f1=sns.barplot(x='track_title', y= 'track_listens',data=tracks_top10, ax=axs[0])\n",
    "f1.set_xticklabels(f1.get_xticklabels(), rotation=90)\n",
    "f1.set_title(\"Top Tracks\")\n",
    "\n",
    "f2=sns.barplot(x='track_title', y= 'track_listens',data=pre_trump_tracks_top10,  ax=axs[1])\n",
    "f2.set_xticklabels(f2.get_xticklabels(), rotation=90)\n",
    "f2.set_title(\"Pre trump Top Tracks\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trump_albums_grouped = pre_trump.groupby(pre_trump['album_id']) \\\n",
    "                          .first()[['album_title', 'album_listens']]\n",
    "pre_trump_albums_top10 = pre_trump_albums_grouped.sort_values(by='album_listens', \n",
    "                                          ascending=False).head(10)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2,  constrained_layout=True, figsize=(12,5))\n",
    "\n",
    "f1=sns.barplot(x='album_title', y= 'album_listens',data=albums_top10, ax=axs[0])\n",
    "f1.set_xticklabels(f1.get_xticklabels(), rotation=90)\n",
    "f1.set_title(\"Top Albums\")\n",
    "\n",
    "f2=sns.barplot(x='album_title', y= 'album_listens',data=pre_trump_albums_top10,  ax=axs[1])\n",
    "f2.set_xticklabels(f2.get_xticklabels(), rotation=90)\n",
    "f2.set_title(\"Pre trump Top Albums\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
