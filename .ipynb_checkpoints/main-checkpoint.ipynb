{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA 2018 -  Evolution of Music.\n",
    "\n",
    "#### Andres Montero, Ariel Alba, Diego Iriarte\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to find the relationships between tweets and music, specifically focus on tweets which reflect a positive sentiment or mood and we'll relate them to the kind of music those people listen to. We believe that music preferences vary depending on people's mood, so we can detect what kind of music people tend to listen to when they are feeling happy or posting tweets with positive sentiment, which in our case are equivalent.\n",
    "For it, we'll work with two datasets:\n",
    "\n",
    "* FMA: A Dataset For Music Analysis\n",
    "* Sentiment140 dataset with 1.6 million tweets\n",
    "\n",
    "Tweets dataset is a labeled set, indicating whether each tweet has a positive sentiment or not.\n",
    "In order to define whether the proposed idea is feasible or not, we follow these steps:\n",
    "\n",
    "**A)** Preprocessing and analyzing FMA dataset. Gather the data that will be used, the dataset is very extense and we must focus on the data that will be used for our study. We clean the data, define the type of variables, normalize them and deal with missing values. From the cleaned data, we get some statistical information of the dataset, such as most listened songs, albums and others. We try to find some relationships between some information of the dataset such as: danceability, energy, number of times listened, location and others, too.\n",
    "\n",
    "**B)** Loading and analyzing of Sentiment140 dataset. We will only focus on tweets which are labeled as positive sentiment and the approach. The dataset contains few information about the tweets such as date, sentiment, userID and tweet, and is limited to tweets of yar 2009. Before doing any further preprocessing of such dataset we decided to check the possible relationships that we could find with FMA dataset.\n",
    "\n",
    "**C)** Find relationships between both datasets. It is important to identify whether the idea of the project is feasible or not. For the idea to be feasible, we need to find a considerable number of positive tweets which are somehow related to music or songs. To measure this relationships our approach is the following:\n",
    "\n",
    "* Count how many tweets are linked to a song\n",
    "* Count how many tweets explicitly say spotify on it.\n",
    "* Find words related to music contained in the tweets (may be a difficult task)\n",
    "\n",
    "**D)** In case, our two first approaches to find the relationships between both datasets don't succeed, we may not be able to try with the third one due to time contraints and task difficulty. If this is the scenario, the project scope will be reduced and will mostly focus on the FMA dataset and a specific event in the past years which may caused an impact on music production and preferences. Such scenario will be defined according to the insights found in part A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import reverse_geocoder as rg\n",
    "import os.path\n",
    "import ast\n",
    "import seaborn as sns\n",
    "\n",
    "from helpers import *\n",
    "from datetime import datetime, date, time\n",
    "from scipy import stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Preprocessing and Analyzing FMA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First part consists of loading the data that is needed for the analysis, cleaning and storing them in dataFrames so we can further work with them.\n",
    "\n",
    "First, we will define some constants and paths that will help us later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = './data/'\n",
    "MUSIC_DIR = '{dir}{file}/'.format(dir=DATA_DIR, \n",
    "                                  file='fma_metadata')\n",
    "PKL_DIR = '{dir}{file}/'.format(dir=DATA_DIR, \n",
    "                               file='pkl')\n",
    "\n",
    "# True if we want to to execute the clean phase and to force \n",
    "# saving the cleaned file\n",
    "CLEAN_PHASE = True\n",
    "DEBUG = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    echonest_path = '{dir}{file}'.format(dir=MUSIC_DIR, \n",
    "                                         file='echonest.csv')\n",
    "    features_path = '{dir}{file}'.format(dir=MUSIC_DIR,\n",
    "                                         file='features.csv')\n",
    "    genres_path = '{dir}{file}'.format(dir=MUSIC_DIR,\n",
    "                                       file='genres.csv')\n",
    "    tracks_path = '{dir}{file}'.format(dir=MUSIC_DIR,\n",
    "                                       file='tracks.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the FMA dataset we find out that metadata csv file is full of unnecesary information for our analysis.\n",
    "\n",
    "Thus, we define which variables, type of variables and name of columns we are going to extract from the FMA csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    # Load datasets into pandas dataframes\n",
    "    echonest_col_names=['track_id', 'danceability', 'energy',\n",
    "                        'valence', 'artist_latitude',\n",
    "                        'artist_longitude', 'artist_name',\n",
    "                        'artist_discovery', 'artist_family',\n",
    "                        'artist_hotness', 'song_currency', \n",
    "                        'song_hotness']\n",
    "    \n",
    "    echonest_dtypes = {'track_id': int, 'danceability': float, \n",
    "                       'energy': float, 'valence': float,\n",
    "                       'artist_latitude': float, 'artist_longitude': float,\n",
    "                       'artist_name': str, 'artist_discovery': float, \n",
    "                       'artist_family': float, 'artist_hotness': float,\n",
    "                       'song_currency': float, 'song_hotness': float}\n",
    "    \n",
    "    echonest_df = pd.read_csv(echonest_path, names=echonest_col_names,\n",
    "                              header=3, dtype=echonest_dtypes, \n",
    "                              usecols=[0, 2, 3, 8, 11, 13, 14,\n",
    "                                       21, 22, 23, 24, 25])\n",
    "\n",
    "    genres_dtypes = {'genre_id': int, '#tracks': int, \n",
    "                     'parent': int, 'top_level': int}\n",
    "    \n",
    "    genres_df = pd.read_csv(genres_path, dtype=genres_dtypes)\n",
    "    \n",
    "    track_col_names = ['track_id', 'album_date_created',\n",
    "                       'album_date_released', 'album_id',\n",
    "                       'album_listens', 'album_title', \n",
    "                       'artist_id', 'artist_latitude',\n",
    "                       'artist_longitude', 'artist_name',\n",
    "                       'track_duration', 'track_genre_top',\n",
    "                       'track_genres_all', 'track_language', \n",
    "                       'track_listens', 'track_tags', \n",
    "                       'track_title']\n",
    "\n",
    "    tracks_dtypes = {'track_id': int, 'album_date_created': str,\n",
    "                     'album_date_released': str, \n",
    "                     'album_id': int, 'album_listens': int, \n",
    "                     'album_title': str, 'artist_id': int,\n",
    "                     'artist_latitude': float, 'artist_longitude': float,\n",
    "                     'artist_name': str, 'track_duration': int, \n",
    "                     'track_genre_top': str, 'track_genres_all': str, \n",
    "                     'track_language': str, 'track_listens': int,\n",
    "                     'track_tags': str, 'track_title': str}\n",
    "\n",
    "    tracks_df = pd.read_csv(tracks_path, names=track_col_names,\n",
    "                            header=2, usecols=[0, 2, 3, 6, 8, 11,\n",
    "                                               21, 22, 24, 26, 38, \n",
    "                                               40, 41, 45, 47, 51,\n",
    "                                               52])\n",
    "    track_genre_rel_df = pd.DataFrame(columns=['track_id', 'genre_id'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, we have 3 dataframes: echonest, tracks and genres which makes reference to the csv files.\n",
    "\n",
    "Now, it is time to clean data!!! And have some information in a more suitable represetation for further analysis.\n",
    "\n",
    "First we start cleaning tracks dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracks clean phase\n",
    "if CLEAN_PHASE:\n",
    "    # Transforms str to datetime\n",
    "    tracks_df['album_date_released'] = pd.to_datetime( \\\n",
    "                                            tracks_df['album_date_released'])\n",
    "    tracks_df['album_date_created'] = pd.to_datetime( \\\n",
    "                                            tracks_df['album_date_created'])\n",
    "    # Transform str to list\n",
    "    tracks_df['track_tags'] = tracks_df['track_tags'] \\\n",
    "                                .apply(lambda x: ast.literal_eval(x))\n",
    "    tracks_df['track_genres_all'] = tracks_df['track_genres_all'] \\\n",
    "                                        .apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "    # Generate track-genre relational dataframe\n",
    "    track_genre_tuple = list(zip(tracks_df['track_id'], \n",
    "                             tracks_df['track_genres_all']))\n",
    "    track_genre_list = [{'track_id': track_id, 'genre_id': genre_id} \n",
    "                         for track_id, genres_id in track_genre_tuple\n",
    "                         for genre_id in genres_id]\n",
    "\n",
    "    track_genre_rel_df = track_genre_rel_df.append(track_genre_list, \n",
    "                                                   ignore_index=True,\n",
    "                                                   sort=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realize that the tracks dataframe containst also information about artists and albums and echonest has info for each track , thus, to have a better organization and not have redundacy, we joined tracks and echonest. Then the joined table was split on 3 new dataframes: tracks, albums and artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    # Normalize dataframes to take out redundancy\n",
    "    # Join echonist data to tracks\n",
    "    echo_tracks = echonest_df.merge(tracks_df, left_on='track_id', \n",
    "                                    right_on='track_id', how='outer')\n",
    "    \n",
    "    print(len(echo_tracks))\n",
    "     \n",
    "    # Select main columns to create new df\n",
    "    artists_df = echo_tracks[['artist_id', 'artist_name_x',\n",
    "                              'artist_latitude_x', 'artist_longitude_x', \n",
    "                              'artist_discovery', 'artist_family', \n",
    "                              'artist_hotness', 'artist_latitude_y',\n",
    "                              'artist_longitude_y', 'artist_name_y']].copy()\n",
    "\n",
    "    albums_df = echo_tracks[['album_id', 'album_date_created',\n",
    "                             'album_date_released', 'album_title',\n",
    "                             'album_listens']].copy()\n",
    "    \n",
    "    tracks_df = echo_tracks[['track_id', 'track_title', \n",
    "                             'track_duration', 'artist_id', \n",
    "                             'album_id', 'track_genre_top',\n",
    "                             'track_genres_all','track_language',\n",
    "                             'track_listens', 'track_tags',\n",
    "                             'danceability', 'energy',\n",
    "                             'valence', 'song_currency',\n",
    "                             'song_hotness']].copy()\n",
    "    \n",
    "    # Drop duplicates\n",
    "    artists_df = artists_df.drop_duplicates('artist_id')\n",
    "    albums_df = albums_df.drop_duplicates('album_id')\n",
    "    \n",
    "    # Reset Index\n",
    "    artists_df = artists_df.reset_index(drop=True)\n",
    "    albums_df = albums_df.reset_index(drop=True)\n",
    "    \n",
    "    # Clean listen count\n",
    "    albums_df['album_listens'] = albums_df['album_listens'] \\\n",
    "                                    .apply(lambda x : neg_to_zero(x))\n",
    "    \n",
    "    tracks_df['track_listens'] = tracks_df['track_listens'] \\\n",
    "                                    .apply(lambda x : neg_to_zero(x))\n",
    "    \n",
    "    # Artist name different on echonest and FullMusicArchive\n",
    "    if DEBUG:\n",
    "        name_comp = not_eq_ign_case(artists_df['artist_name_x'],\n",
    "                                    artists_df['artist_name_y'])\n",
    "        artist_name_diff = artists_df[name_comp]\n",
    "        \n",
    "        print('# Different artist names: {}\\n' \\\n",
    "                  .format(len(artist_name_diff)))\n",
    "\n",
    "        print('Example:\\n{}'.format(artist_name_diff[['artist_name_x',\n",
    "                                                      'artist_name_y']].head(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have 4 main datasets: genres, artists, albums and tracks.\n",
    "\n",
    "FMA dataset (https://lts2.epfl.ch/datasets/fma/) was gathered by joining a lot of information of many music API services like Echonest(now Spotify), LastFM, MusicBrainz and others more, thus, there are some columns that have data redundacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artist location different on echonest and FullMusicArchive\n",
    "if DEBUG and CLEAN_PHASE:\n",
    "    lat_comp = artists_df['artist_latitude_x'] != artists_df['artist_latitude_y']\n",
    "    long_comp = artists_df['artist_longitude_x'] != artists_df['artist_longitude_y']\n",
    "    latlong_comp = lat_comp | long_comp\n",
    "    latlong_diff = artists_df[latlong_comp]\n",
    "\n",
    "    print('# Different Lat Long values: {}\\n' \\\n",
    "              .format(len(latlong_diff)))\n",
    "\n",
    "    print('Example:\\n{}'.format(artist_name_diff[['artist_latitude_x',\n",
    "                                                  'artist_latitude_y',\n",
    "                                                  'artist_longitude_x',\n",
    "                                                  'artist_longitude_y']].head(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also there is some spatial information encoded on certain columns, to handle them, we used a service to retrieve the exact location (Country, city, state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    # Getting city, state, country from artist longitude and latitude\n",
    "    cities=[]\n",
    "    states=[]\n",
    "    countries=[]\n",
    "    \n",
    "    for i in range (0, len(artists_df)):\n",
    "        if np.isnan(artists_df.artist_latitude_y[i]):\n",
    "            city = np.nan\n",
    "            state = np.nan\n",
    "            country = np.nan\n",
    "        else:\n",
    "            coordinates = (artists_df.artist_latitude_y[i], \n",
    "                           artists_df.artist_longitude_y[i])\n",
    "            results = rg.search(coordinates, mode=1)\n",
    "            city = results[0]['name']\n",
    "            state = results[0]['admin1']\n",
    "            country = results[0]['cc']\n",
    "        \n",
    "        cities.append(city)\n",
    "        states.append(state)\n",
    "        countries.append(country)\n",
    "    \n",
    "    artists_df.insert(loc=5, column='city', \n",
    "                      value=pd.Series(cities))\n",
    "    artists_df.insert(loc=6, column='state',\n",
    "                      value=pd.Series(states))\n",
    "    artists_df.insert(loc=7, column='country', \n",
    "                      value=pd.Series(countries))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from Spitfy and LastFM API with updated information\n",
    "YEARS = [2017, 2018]\n",
    "dfs = {}\n",
    "\n",
    "for year in YEARS:\n",
    "    albums_year_path = '{dir}albums_{year}_df.pkl'.format(dir=PKL_DIR,\n",
    "                                                          year=year)\n",
    "    artists_year_path = '{dir}artists_{year}_df.pkl'.format(dir=PKL_DIR,\n",
    "                                                            year=year)\n",
    "    tracks_year_path = '{dir}tracks_{year}_df.pkl'.format(dir=PKL_DIR,\n",
    "                                                          year=year)\n",
    "\n",
    "    dfs[year] = {'tracks': pd.read_pickle(tracks_year_path),\n",
    "                 'albums': pd.read_pickle(albums_year_path),\n",
    "                 'artists': pd.read_pickle(artists_year_path)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    tracks_post = pd.DataFrame(columns=tracks_df.columns) \n",
    "    albums_post = pd.DataFrame(columns=albums_df.columns)\n",
    "    artists_post = pd.DataFrame(columns=artists_df.columns)\n",
    "    result = []\n",
    "    \n",
    "    for index, year in enumerate(YEARS):\n",
    "        tracks = dfs[year]['tracks']\n",
    "        albums = dfs[year]['albums']\n",
    "        artists = dfs[year]['artists']\n",
    "        \n",
    "        # New tracks cleaning\n",
    "        # Transform miliseconds duration to minutes\n",
    "        tracks['track_duration'] = tracks['track_duration'] / 60000\n",
    "\n",
    "        # Normalize song_hotness to be a value between 1 and 0\n",
    "        tracks['song_hotness'] = tracks['song_hotness'] / 100 \n",
    "\n",
    "        # New albums cleaning\n",
    "        albums['album_date_released'] = pd.to_datetime( \\\n",
    "                                                albums['album_date_released'])\n",
    "\n",
    "        # New artist cleaning\n",
    "        # Normalize artist_hotness to be a value between 1 and 0\n",
    "        artists['artist_hotness'] = artists['artist_hotness'] / 100\n",
    "\n",
    "        # Merge the datasets of all years to have just one dataset for tracks ,\n",
    "        # albums and artists\n",
    "        tracks_post = pd.concat([tracks_post, tracks], axis=0, \n",
    "                                sort=False)\n",
    "        artists_post = pd.concat([artists_post, artists], axis=0, \n",
    "                                 sort=False)\n",
    "        albums_post = pd.concat([albums_post, albums], axis=0, \n",
    "                                sort=False)\n",
    "        \n",
    "    # Drop duplicates\n",
    "    tracks_post.drop_duplicates('track_id', inplace=True)\n",
    "    artists_post.drop_duplicates('artist_id', inplace=True)\n",
    "    albums_post.drop_duplicates('album_id', inplace=True)\n",
    "    \n",
    "    # Sample\n",
    "    tracks_post = tracks_post.sample(frac=0.94)\n",
    "    artists_post = artists_post.sample(frac=0.25)\n",
    "    albums_post = albums_post.sample(frac=0.175)\n",
    "    \n",
    "    # Generate relational dataframe track-genres\n",
    "    # Look at genres on tags and add them to track_genres_all\n",
    "    genre_list = genres_df['title'].tolist()\n",
    "    genres = [genre.lower() for genre in genre_list]\n",
    "\n",
    "    for i, row in tracks_post.iterrows():\n",
    "        genre_set = set(genres)\n",
    "        tag_set = set(row['track_tags'])\n",
    "        genres_from_tags = list(genre_set.intersection(tag_set))\n",
    "        track_uniq_genres = uniq(row['track_genres_all'] + genres_from_tags)\n",
    "        [result.append({'track_id': row['track_id'],\n",
    "                        'genre_name': genre}) for genre in track_uniq_genres]\n",
    "    \n",
    "    genres_merge = genres_df.copy()\n",
    "    genres_merge['title'] = genres_merge['title'].str.lower()\n",
    "    track_genre_name = pd.DataFrame(data=result)\n",
    "    track_genre_name['genre_name'] = track_genre_name['genre_name'].str.lower()\n",
    "    track_genre_rel_post = track_genre_name.merge(genres_merge, left_on='genre_name',\n",
    "                                                right_on='title')[['track_id', 'genre_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_PHASE:\n",
    "    albums_df = pd.concat([albums_df, albums_post], axis=0,\n",
    "                          sort=False)\n",
    "    albums_df.drop_duplicates('album_id', inplace=True)\n",
    "    albums_df.drop(columns=['spoti_album_id'], inplace=True)\n",
    "    albums_df['album_listens'] = pd.to_numeric(albums_df['album_listens'])\n",
    "    \n",
    "    \n",
    "    artists_df = pd.concat([artists_df, artists_post], axis=0, \n",
    "                           sort=False)\n",
    "    artists_df.drop_duplicates('artist_id', inplace=True)\n",
    "    artists_df.drop(columns=['spoti_artist_id', 'artist_name_x', \n",
    "                             'artist_longitude_x', 'artist_latitude_x'], \n",
    "                    inplace=True)\n",
    "    artists_df.rename({'artist_latitude_y': 'artist_latitude', \n",
    "                       'artist_longitude_y': 'artist_longitude',\n",
    "                       'artist_name_y': 'artist_name'}, \n",
    "                      axis='columns', \n",
    "                      inplace=True)\n",
    "    \n",
    "    \n",
    "    tracks_df = pd.concat([tracks_df, tracks_post], axis=0, \n",
    "                           sort=False)\n",
    "    tracks_df.drop_duplicates('track_id', inplace=True)\n",
    "    tracks_df.drop(columns=['spoti_track_id', 'spoti_album_id',\n",
    "                            'spoti_artist_id', 'track_genres_all', \n",
    "                            'track_genre_top'], inplace=True)\n",
    "    tracks_df['track_duration'] = pd.to_numeric(tracks_df['track_duration'])\n",
    "    tracks_df['track_listens'] = pd.to_numeric(tracks_df['track_listens'])\n",
    "    tracks_df['song_hotness'] = pd.to_numeric(tracks_df['song_hotness'])\n",
    "    \n",
    "    \n",
    "    track_genre_rel_df = pd.concat([track_genre_rel_df, track_genre_rel_post], \n",
    "                                   axis=0, sort=False)\n",
    "    track_genre_rel_df.drop_duplicates(subset=['track_id', 'genre_id'], \n",
    "                                       inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after all preprocessing steps, we can save the information to be used for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read  and wirte files depending on the existance of own path\n",
    "echonest_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                        file='echonest_df.pkl')\n",
    "genres_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                     file='genres_df.pkl')\n",
    "albums_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                     file='albums_df.pkl')\n",
    "artists_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                     file='artists_df.pkl')\n",
    "tracks_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                      file='tracks_df.pkl')\n",
    "track_genre_rel_df_path = '{dir}{file}'.format(dir=PKL_DIR, \n",
    "                                               file='track_genre_rel_df.pkl')\n",
    "if CLEAN_PHASE:\n",
    "    genres_df.to_pickle(genres_df_path)\n",
    "elif os.path.exists(echonest_df_path):\n",
    "    genres_df = pd.read_pickle(genres_df_path)\n",
    "else:\n",
    "    print('There is no genres pandas data')\n",
    "    \n",
    "if CLEAN_PHASE:\n",
    "    albums_df.to_pickle(albums_df_path)\n",
    "elif os.path.exists(albums_df_path):\n",
    "    albums_df = pd.read_pickle(albums_df_path)\n",
    "else:\n",
    "    print('There is no albums pandas data')\n",
    "    \n",
    "if CLEAN_PHASE:\n",
    "    artists_df.to_pickle(artists_df_path)\n",
    "elif os.path.exists(artists_df_path):\n",
    "    artists_df = pd.read_pickle(artists_df_path)\n",
    "else:\n",
    "    print('There is no artists pandas data')\n",
    "    \n",
    "if CLEAN_PHASE:\n",
    "    tracks_df.to_pickle(tracks_df_path)\n",
    "elif os.path.exists(tracks_df_path):\n",
    "    tracks_df = pd.read_pickle(tracks_df_path)\n",
    "else:\n",
    "    print('There is no tracks pandas data')\n",
    "    \n",
    "if CLEAN_PHASE:\n",
    "    track_genre_rel_df.to_pickle(track_genre_rel_df_path)\n",
    "elif os.path.exists(track_genre_rel_df_path):\n",
    "    track_genre_rel_df_path = pd.read_pickle(track_genre_rel_df_path)\n",
    "else:\n",
    "    print('There is no tracks-genres pandas data')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify some statistics on all dataframes, like the missing values after preprocessing, taking echonest as one dataframe, just for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(genres_df, 'Genres', DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(artists_df, 'Artists', DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(albums_df, 'Albums', DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(tracks_df, 'Tracks', DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(track_genre_rel_df, 'Track-Genre', DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_dist = albums_df.groupby(albums_df['album_date_released'].dt.year).size()\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "ax = album_dist.plot(kind='bar')\n",
    "plt.title(\"Distribution of Albums per Year\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_albums = tracks_df.merge(albums_df)\n",
    "tracks_dist = tracks_albums.groupby(tracks_albums['album_date_released'].dt.year).size()\n",
    "plt.figure(figsize=(9, 7))\n",
    "ax = tracks_dist.plot(kind='bar')\n",
    "plt.title(\"Distribution of Tracks per Year\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_artist = tracks_df.merge(artists_df, left_on='artist_id', \n",
    "                               right_on='artist_id')\n",
    "country_grouped = track_artist.groupby(track_artist['country']).size()\n",
    "country_top10 = country_grouped.sort_values(ascending=False) \\\n",
    "                                     .head(10)\n",
    "country_top10.plot(kind='bar', \n",
    "                   title=\"Top 10 countries that produce tracks\")\n",
    "plt.ylabel('Number of Tracks')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_grouped = albums_df.groupby(albums_df['album_id']) \\\n",
    "                          .first()[['album_title', 'album_listens']]\n",
    "albums_top10 = albums_grouped.sort_values(by='album_listens', \n",
    "                                          ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Top 10 Albums listened\")\n",
    "plt.grid()\n",
    "ax = sns.barplot(x='album_title', y= 'album_listens',\n",
    "                 data=albums_top10)\n",
    "plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_grouped = tracks_df.groupby(tracks_df['track_id']) \\\n",
    "                          .first()[['track_title', 'track_listens']]\n",
    "tracks_top10 = tracks_grouped.sort_values(by='track_listens', \n",
    "                                          ascending=False).head(10)\n",
    "\n",
    "\n",
    "albums_top10.plot(x='album_title', kind='bar', title=\"Top 10 Albums\")\n",
    "plt.grid()\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title(\"Top 10 tracks listened\")\n",
    "plt.grid()\n",
    "ax = sns.barplot(x='track_title', y= 'track_listens',\n",
    "                 data=tracks_top10)\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation between danceability and duration of the song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df.insert(loc=15, column='track_duration_minutes',\n",
    "                 value=(tracks_df['track_duration'] / 60))\n",
    "\n",
    "tracks_df['track_duration_minutes'] = pd.to_numeric( \\\n",
    "                                            tracks_df['track_duration_minutes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df['track_duration_minutes'] = tracks_df['track_duration_minutes'] \\\n",
    "                                                .apply(lambda x : np.rint(x))\n",
    "sns.regplot(x='danceability', y='track_duration_minutes',\n",
    "            data=tracks_df, ci=95, \n",
    "            line_kws = {'color': 'green'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df_correlation = tracks_df.dropna()\n",
    "spearman_coeff = stats.spearmanr(tracks_df_correlation['danceability'], \n",
    "                                 tracks_df_correlation['track_duration_minutes'])\n",
    "print('The spearman correlation is: {}'.format(spearman_coeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coeff = stats.pearsonr(tracks_df_correlation['danceability'], \n",
    "                                 tracks_df_correlation['track_duration_minutes'])\n",
    "print('The pearson correlation is: {}'.format(pearson_coeff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation between valence and other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valence refers to the degree of positive or negative emotions one perceives from a song. We'll try to find some relations between such varible and others.\n",
    "Relation between track_listens and valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='valence', y='track_listens',\n",
    "            data=tracks_df, ci=95, \n",
    "            line_kws ={'color': 'green'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the plot, it is difficult to find a relationships between the valence of the song and the number of listens. We also tried to find relation between valence and energy, or valence and danceability and we found that such relationships are highly variable and do not show any dependance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean value of valence per genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_valence = tracks_df.groupby('track_genre_top', \n",
    "                                  as_index=False)['valence'].mean()\n",
    "genre_valence.plot(x='track_genre_top', kind='bar', \n",
    "                   title='Valence per genre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_album = tracks_df.merge(albums_df, left_on='album_id',\n",
    "                              right_on='album_id')\n",
    "\n",
    "genre_year = track_album[['track_genres_all', 'album_date_released']]\n",
    "genre_year.insert(loc=2, column='album_released_year',\n",
    "                  value=(genre_year['album_date_released'].dt.year))\n",
    "genre_year.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genre = genre_year.groupby(genre_year['track_genres_all']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genre_sorted = top_genre.sort_values(ascending=False).head(10)\n",
    "top_genre_sorted.plot(kind='bar', title=\"Top 10 Genres\")\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_album.sort_values(by='album_date_released', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_album.sort_values(by='album_date_created').head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_df.sort_values(by = ['album_date_released']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tracks_albums = tracks_df.merge(albums_df, how='inner')\n",
    "tracks_albums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_albums_summer = tracks_albums.loc[lambda tracks_albums: (tracks_albums.album_date_released.dt.month >5)\\\n",
    "                 & (tracks_albums.album_date_released.dt.month <10)]\n",
    "tracks_albums_summer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tracks_albums_summer.groupby([(tracks_albums_summer['album_date_released'].dt.year.rename('year')),\\\n",
    "                          (tracks_albums_summer['album_date_released'].dt.month.rename('month'))]).mean()\n",
    "\n",
    "test_1 = test[['valence']]\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "ax = test_1.plot(kind='bar')\n",
    "plt.title(\"Valence Summer Hits\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_albums_summer_2010 = tracks_albums.loc[lambda tracks_albums: (tracks_albums.album_date_released.dt.month >5)\\\n",
    "                 & (tracks_albums.album_date_released.dt.month <10) \\\n",
    "                 & (tracks_albums.album_date_released.dt.year >2009)]\n",
    "tracks_albums_summer_2010.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2010 = tracks_albums_summer_2010.groupby([(tracks_albums_summer_2010['album_date_released'].dt.year.rename('year')),\\\n",
    "                          (tracks_albums_summer_2010['album_date_released'].dt.month.rename('month'))]).mean()\n",
    "\n",
    "test_valence_2010 = test_2010[['valence']]\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "ax = test_valence_2010.plot(kind='line')\n",
    "plt.title(\"Valence Summer Hits\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_danceability_2010 = test_2010[['danceability']]\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "ax = test_danceability_2010.plot(kind='line')\n",
    "plt.title(\"Danceability Summer Hits\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_energy_2010 = test_2010[['energy']]\n",
    "\n",
    "plt.figure(figsize=(9, 7))\n",
    "ax = test_energy_2010.plot(kind='bar')\n",
    "plt.title(\"Energy Summer Hits\")\n",
    "plt.grid()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test = test_valence_2010.groupby('year').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
